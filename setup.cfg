[metadata]
name = llmebench
version = 1.1.0
author = Fahim Dalvi
author_email = faimaduddin@hbku.edu.qa
description = A Flexible Framework for Accelerating LLMs Benchmarking
long_description = file: README.md
long_description_content_type = text/markdown
url = https://llmebench.qcri.org
project_urls =
    Documentation = https://github.com/qcri/LLMeBench
    Bug Tracker = https://github.com/qcri/LLMeBench
classifiers =
    Programming Language :: Python :: 3
    License :: OSI Approved :: BSD License
    Operating System :: OS Independent

[options]
packages = find:
package_dir =
    =.
install_requires =
    datasets==2.14.6
    nltk==3.8.1
    openai==1.59.7
    anthropic==0.43.0
    pandas==2.0.2
    pooch==1.7.0
    python-dotenv==1.0.0
    scikit-learn==1.2.2
    tenacity==8.2.2
    websockets==11.0.3
    evaluate==0.4.3
    rouge-score==0.1.2
    absl-py==2.1.0
    GitPython==3.1.43
# For now, make sure NumPy 2 is not installed
    numpy<2

python_requires = >=3.8

[options.extras_require]
dev =
    langcodes==3.3.0
    pytest==7.3.1
    pytest-cov==4.1.0
    pytest-subtests==0.11.0
    ufmt==1.3.2
fewshot =
    langchain==0.0.198
    sentence_transformers==3.2.1
    faiss-cpu==1.8.0

[options.packages.find]
where = .
exclude = tests*

[tool:pytest]
testpaths = tests
filterwarnings =
    ignore::sklearn.exceptions.UndefinedMetricWarning
    ignore:divide by zero:RuntimeWarning
    ignore:Degrees of freedom:RuntimeWarning
    ignore:invalid value encountered in multiply:RuntimeWarning
